//
//  OCRService.swift
//  WarrantyWallet
//
//  Created by Ethan on 20/10/2025.
//

import Foundation
import Vision
import UIKit
import Combine

class OCRService: ObservableObject {
    
    @Published var isProcessing = false
    @Published var lastExtractedText = ""
    
    // MARK: - Text Extraction from Images using Vision Framework
    
    func extractTextFromImage(_ imageData: Data) async throws -> String {
        print("üîç OCRService: Starting text extraction from image data")
        print("üìä OCRService: Image data size: \(imageData.count) bytes")
        
        await MainActor.run {
            isProcessing = true
        }
        print("‚è≥ OCRService: Processing state set to true")
        
        defer {
            Task { @MainActor in
                isProcessing = false
            }
        }
        
        guard let image = UIImage(data: imageData),
              let cgImage = image.cgImage else {
            print("‚ùå OCRService: Failed to create UIImage or CGImage from data")
            throw OCRError.invalidImageData
        }
        print("‚úÖ OCRService: Successfully created CGImage from data")
        
        let extractedText = try await withCheckedThrowingContinuation { (continuation: CheckedContinuation<String, Error>) in
            print("üîß OCRService: Creating VNRecognizeTextRequest")
            let request = VNRecognizeTextRequest { request, error in
                if let error = error {
                    print("‚ùå OCRService: Vision framework error: \(error.localizedDescription)")
                    continuation.resume(throwing: error)
                    return
                }
                
                guard let observations = request.results as? [VNRecognizedTextObservation] else {
                    print("‚ùå OCRService: No text observations found in image")
                    continuation.resume(throwing: OCRError.noTextFound)
                    return
                }
                
                print("üìù OCRService: Found \(observations.count) text observations")
                let extractedText = observations.compactMap { observation in
                    observation.topCandidates(1).first?.string
                }.joined(separator: "\n")
                
                print("üìÑ OCRService: Extracted text length: \(extractedText.count) characters")
                print("üìÑ OCRService: Extracted text preview: \(String(extractedText.prefix(100)))...")
                continuation.resume(returning: extractedText)
            }
            
            // Configure for accurate text recognition
            request.recognitionLevel = .accurate
            request.recognitionLanguages = ["en"]
            request.usesLanguageCorrection = true
            print("‚öôÔ∏è OCRService: Configured request with accurate recognition level")
            
            let requestHandler = VNImageRequestHandler(cgImage: cgImage, options: [:])
            
            do {
                print("üöÄ OCRService: Performing text recognition request")
                try requestHandler.perform([request])
                print("‚úÖ OCRService: Text recognition request completed successfully")
            } catch {
                print("‚ùå OCRService: Failed to perform text recognition: \(error.localizedDescription)")
                continuation.resume(throwing: error)
            }
        }
        
        print("üìù OCRService: Final extracted text: \(extractedText)")
        await MainActor.run {
            lastExtractedText = extractedText
        }
        print("‚úÖ OCRService: Text extraction completed successfully")
        
        return extractedText
    }
    
    // MARK: - Alternative method using UIImage directly
    
    func extractTextFromImage(_ image: UIImage) async throws -> String {
        await MainActor.run {
            isProcessing = true
        }
        
        defer {
            Task { @MainActor in
                isProcessing = false
            }
        }
        
        guard let cgImage = image.cgImage else {
            throw OCRError.invalidImageData
        }
        
        let extractedText = try await withCheckedThrowingContinuation { (continuation: CheckedContinuation<String, Error>) in
            let request = VNRecognizeTextRequest { request, error in
                if let error = error {
                    continuation.resume(throwing: error)
                    return
                }
                
                guard let observations = request.results as? [VNRecognizedTextObservation] else {
                    continuation.resume(throwing: OCRError.noTextFound)
                    return
                }
                
                let extractedText = observations.compactMap { observation in
                    observation.topCandidates(1).first?.string
                }.joined(separator: "\n")
                
                continuation.resume(returning: extractedText)
            }
            
            // Configure for accurate text recognition
            request.recognitionLevel = .accurate
            request.recognitionLanguages = ["en"]
            request.usesLanguageCorrection = true
            print("‚öôÔ∏è OCRService: Configured request with accurate recognition level")
            
            let requestHandler = VNImageRequestHandler(cgImage: cgImage, options: [:])
            
            do {
                print("üöÄ OCRService: Performing text recognition request")
                try requestHandler.perform([request])
                print("‚úÖ OCRService: Text recognition request completed successfully")
            } catch {
                print("‚ùå OCRService: Failed to perform text recognition: \(error.localizedDescription)")
                continuation.resume(throwing: error)
            }
        }
        
        print("üìù OCRService: Final extracted text: \(extractedText)")
        await MainActor.run {
            lastExtractedText = extractedText
        }
        print("‚úÖ OCRService: Text extraction completed successfully")
        
        return extractedText
    }
}

// MARK: - OCR Errors

enum OCRError: Error, LocalizedError {
    case invalidImageData
    case noTextFound
    case visionFrameworkError
    
    var errorDescription: String? {
        switch self {
        case .invalidImageData:
            return "Invalid image data provided"
        case .noTextFound:
            return "No text found in the image"
        case .visionFrameworkError:
            return "Vision framework error occurred"
        }
    }
}
